mutate(created_date = as.Date(as_datetime(createdAtMillis / 1000)))
# Extract unique dates to determine date range
date_range <- ratings_data %>%
summarize(start_date = min(created_date), end_date = max(created_date))
# Display the date range
print(date_range)
# Define the path to the ratings file
ratings_file <- "https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00014.tsv"
# Read in the TSV file
ratings_data <- read_tsv(ratings_file)
# Define the path to the ratings file
ratings_file <- "https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00013.tsv"
# Read in the TSV file
ratings_data <- read_tsv(ratings_file)
# Convert to a normal date/time
ratings_data <- ratings_data %>%
mutate(created_date = as.Date(as_datetime(createdAtMillis / 1000)))
# Extract unique dates to determine date range
date_range <- ratings_data %>%
summarize(start_date = min(created_date), end_date = max(created_date))
# Display the date range
print(date_range)
library(data.table)
# Now we know that ratings files all have ratings from recent weeks, which means we
# have to combine them all
# Define a vector with paths to all rating files
ratings_urls <- c(
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00000.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00001.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00002.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00003.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00004.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00005.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00006.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00007.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00008.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00009.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00010.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00011.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00012.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00013.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00014.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00015.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00016.tsv"
)
# Define the target date
target_date <- as.Date("2024-10-31")
# Initialize an empty list to store data from October 31
oct_31_data <- list()
# Process each URL
for (url in ratings_urls) {
# Read in data from the URL in chunks using fread
data <- fread(url, select = c("createdAtMillis", "noteId", "participantId", "agree", "disagree", "helpful"))
# Convert the createdAtMillis column to date format
data[, created_date := as.Date(as_datetime(createdAtMillis / 1000))]
# Filter for October 31 data
oct_31_ratings <- data[created_date == target_date]
# Append the filtered data to our list
oct_31_data[[url]] <- oct_31_ratings
}
warnings()
View(oct_31_ratings)
# Process each URL
for (url in ratings_urls) {
# Read in data from the URL in chunks using fread
data <- fread(url)
# Convert the createdAtMillis column to date format
data[, created_date := as.Date(as_datetime(createdAtMillis / 1000))]
# Filter for October 31 data
oct_31_ratings <- data[created_date == target_date]
# Append the filtered data to our list
oct_31_data[[url]] <- oct_31_ratings
}
# Define the target date
target_date <- as.Date("2024-10-31")
# Initialize an empty list to store data from October 31
oct_31_data <- list()
# Process each URL
for (url in ratings_urls) {
# Read in data from the URL in chunks using fread
data <- fread(url)
# Convert the createdAtMillis column to date format
data[, created_date := as.Date(as_datetime(createdAtMillis / 1000))]
# Filter for October 31 data
oct_31_ratings <- data[created_date == target_date]
# Append the filtered data to our list
oct_31_data[[url]] <- oct_31_ratings
}
# Define a vector with paths to all rating files
ratings_urls <- c(
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00000.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00001.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00002.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00003.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00004.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00005.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00006.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00007.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00008.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00009.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00010.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00011.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00012.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00013.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00014.tsv",
"https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteRatings/ratings-00015.tsv"
)
# Define the target date
target_date <- as.Date("2024-10-31")
# Initialize an empty list to store data from October 31
oct_31_data <- list()
# Process each URL
for (url in ratings_urls) {
# Read in data from the URL in chunks using fread
data <- fread(url)
# Convert the createdAtMillis column to date format
data[, created_date := as.Date(as_datetime(createdAtMillis / 1000))]
# Filter for October 31 data
oct_31_ratings <- data[created_date == target_date]
# Append the filtered data to our list
oct_31_data[[url]] <- oct_31_ratings
}
View(oct_31_ratings)
oct_31_data_combined <- oct_31_ratings %>%
left_join(notes_data, by = "noteId") %>%
left_join(note_status_data, by = "noteId")
notes_data <- fread("https://ton.twimg.com/birdwatch-public-data/2024/11/03/notes/notes-00000.tsv")
note_status_data <- fread("https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteStatusHistory/noteStatusHistory-00000.tsv")
# Join with October 31 ratings on `noteId`
oct_31_data_combined <- oct_31_ratings %>%
left_join(notes_data, by = "noteId") %>%
left_join(note_status_data, by = "noteId")
View(oct_31_data_combined)
# Filter for "not helpful" ratings and group by noteId with timestamp windowing
coordinated_ratings <- oct_31_data_combined %>%
filter(notHelpful == 1) %>%
group_by(noteId) %>%
arrange(createdAtMillis) %>%
mutate(time_diff = createdAtMillis - lag(createdAtMillis, default = first(createdAtMillis)),
time_window = cumsum(ifelse(time_diff > 3600000, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Arbitrary threshold; adjust to detect significant clusters
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtMillis) %>%
mutate(time_diff = createdAtMillis - lag(createdAtMillis, default = first(createdAtMillis)),
time_window = cumsum(ifelse(time_diff > 3600000, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Arbitrary threshold; adjust to detect significant clusters
# View notes with significant clusters of "not helpful" ratings
print(coordinated_ratings)
View(coordinated_ratings)
library(ggplot2)
ggplot(coordinated_ratings, aes(x = createdAtMillis / 1000, y = n, color = factor(noteId))) +
geom_line() +
labs(x = "Time (seconds since epoch)", y = "Number of Not Helpful Ratings",
title = "Patterns in 'Not Helpful' Ratings on October 31") +
theme_minimal()
# Convert milliseconds to POSIXct date-time format
coordinated_ratings <- coordinated_ratings %>%
mutate(createdAtDateTime = as.POSIXct(createdAtMillis / 1000, origin = "1970-01-01"))
View(coordinated_ratings)
# Ensure createdAtMillis exists in oct_31_data_combined and convert it to POSIXct first
oct_31_data_combined <- oct_31_data_combined %>%
mutate(createdAtDateTime = as.POSIXct(createdAtMillis / 1000, origin = "1970-01-01"))
# Filter for "not helpful" ratings, group by noteId and time window
coordinated_ratings <- oct_31_data_combined %>%
filter(notHelpful == 1) %>%
group_by(noteId) %>%
arrange(createdAtDateTime) %>%
mutate(time_diff = as.numeric(difftime(createdAtDateTime, lag(createdAtDateTime), units = "secs")),
time_window = cumsum(ifelse(time_diff > 3600, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Adjust threshold as needed
ggplot(coordinated_ratings, aes(x = createdAtDateTime, y = n, color = factor(noteId))) +
geom_line() +
labs(x = "Time", y = "Number of Not Helpful Ratings",
title = "Patterns in 'Not Helpful' Ratings on October 31") +
theme_minimal()
View(coordinated_ratings)
# Filter for "not helpful" ratings, group by noteId and time window
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtDateTime) %>%
mutate(time_diff = as.numeric(difftime(createdAtDateTime, lag(createdAtDateTime), units = "secs")),
time_window = cumsum(ifelse(time_diff > 3600, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Adjust threshold as needed
View(coordinated_ratings)
# Ensure createdAtMillis exists in oct_31_data_combined and convert it to POSIXct first
oct_31_data_combined <- oct_31_data_combined %>%
mutate(createdAtDateTime = as.POSIXct(createdAtMillis / 1000, origin = "1970-01-01"))
# Filter for "not helpful" ratings, group by noteId and time window
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtDateTime) %>%
mutate(time_diff = as.numeric(difftime(createdAtDateTime, lag(createdAtDateTime), units = "secs")),
time_window = cumsum(ifelse(time_diff > 3600, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Adjust threshold as needed
View(coordinated_ratings)
if (nrow(not_helpful_ratings) > 0) {
# Calculate time_diff and time_window correctly, handling NA values
coordinated_ratings <- not_helpful_ratings %>%
group_by(noteId) %>%
arrange(createdAtDateTime) %>%
mutate(time_diff = as.numeric(difftime(createdAtDateTime, lag(createdAtDateTime), units = "secs")),
time_diff = ifelse(is.na(time_diff), 0, time_diff),  # Set first time_diff to 0
time_window = cumsum(ifelse(time_diff > 3600, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 2)  # Adjust threshold for testing
# Print a preview to check the results
print(head(coordinated_ratings))
} else {
print("No 'not helpful' ratings found for October 31.")
}
test <-oct_31_data_combined %>%
filter(noteId == 1851783417328795676)
test <-oct_31_data_combined %>%
filter(noteId == "1851783417328795676")
View(test)
# Convert milliseconds to POSIXct date-time format
coordinated_ratings <- coordinated_ratings %>%
mutate(createdAtDateTime = as.POSIXct(createdAtMillis.y / 1000, origin = "1970-01-01"))
# Ensure createdAtMillis exists in oct_31_data_combined and convert it to POSIXct first
oct_31_data_combined <- oct_31_data_combined %>%
mutate(createdAtDateTime = as.POSIXct(createdAtMillis.y / 1000, origin = "1970-01-01"))
# Filter for "not helpful" ratings, group by noteId and time window
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtDateTime) %>%
mutate(time_diff = as.numeric(difftime(createdAtDateTime, lag(createdAtDateTime), units = "secs")),
time_window = cumsum(ifelse(time_diff > 3600, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Adjust threshold as needed
View(coordinated_ratings)
View(oct_31_data_combined)
oct_31_data_combined <- oct_31_ratings %>%
left_join(notes_data, by = "noteId") %>%
left_join(note_status_data, by = "noteId")
# Filter for "not helpful" ratings and group by noteId with timestamp windowing
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtMillis.y) %>%
mutate(time_diff = createdAtMillis.y - lag(createdAtMillis.y, default = first(createdAtMillis.y)),
time_window = cumsum(ifelse(time_diff > 3600000, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Arbitrary threshold; adjust to detect significant clusters
View(coordinated_ratings)
View(oct_31_data_combined)
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtMillis.y) %>%
mutate(time_diff = createdAtMillis.x - lag(createdAtMillis.x, default = first(createdAtMillis.x)),
time_window = cumsum(ifelse(time_diff > 3600000, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Arbitrary threshold; adjust to detect significant clusters
View(coordinated_ratings)
# Filter for "not helpful" ratings and group by noteId with timestamp windowing
coordinated_ratings <- oct_31_data_combined %>%
filter(helpfulnessLevel == "NOT_HELPFUL") %>%
group_by(noteId) %>%
arrange(createdAtMillis.x) %>%
mutate(time_diff = createdAtMillis.x - lag(createdAtMillis.x, default = first(createdAtMillis.x)),
time_window = cumsum(ifelse(time_diff > 3600000, 1, 0))) %>%  # 1-hour windows
count(noteId, time_window) %>%
filter(n > 5)  # Arbitrary threshold; adjust to detect significant clusters
View(coordinated_ratings)
library(ggplot2)
ggplot(coordinated_ratings, aes(x = createdAtMillis.x / 1000, y = n, color = factor(noteId))) +
geom_line() +
labs(x = "Time (seconds since epoch)", y = "Number of Not Helpful Ratings",
title = "Patterns in 'Not Helpful' Ratings on October 31") +
theme_minimal()
ggplot(coordinated_ratings, aes(x = "createdAtMillis.x" / 1000, y = n, color = factor(noteId))) +
geom_line() +
labs(x = "Time (seconds since epoch)", y = "Number of Not Helpful Ratings",
title = "Patterns in 'Not Helpful' Ratings on October 31") +
theme_minimal()
ggplot(coordinated_ratings, aes(x = oct_31_data_combined$createdAtMillis.x / 1000, y = n, color = factor(noteId))) +
geom_line() +
labs(x = "Time (seconds since epoch)", y = "Number of Not Helpful Ratings",
title = "Patterns in 'Not Helpful' Ratings on October 31") +
theme_minimal()
notes_data <- notes_data %>%
rename(noteCreatedAt = createdAtMillis)  # Timestamp when the note was created
note_status_data <- note_status_data %>%
rename(statusCreatedAt = createdAtMillis)  # Timestamp related to status history
oct_31_data_combined <- oct_31_data_combined %>%
rename(ratingCreatedAt = createdAtMillis)  # Timestamp when the rating was created
View(oct_31_data_combined)
notes_data <- notes_data %>%
rename(noteCreatedAt = createdAtMillis)  # Timestamp when the note was created
oct_31_data_combined <- oct_31_ratings %>%
left_join(notes_data, by = "noteId") %>%
left_join(note_status_data, by = "noteId")
View(oct_31_data_combined)
View(notes_data)
View(note_status_data)
View(notes_data)
notes_data <- fread("https://ton.twimg.com/birdwatch-public-data/2024/11/03/notes/notes-00000.tsv")
note_status_data <- fread("https://ton.twimg.com/birdwatch-public-data/2024/11/03/noteStatusHistory/noteStatusHistory-00000.tsv")
notes_data <- notes_data %>%
rename(noteCreatedAt = createdAtMillis) %>%
select(noteId, summary)
View(notes_data)
note_status_data <- note_status_data %>%
rename(noteCreatedAt = createdAtMillis)  # Timestamp related to status history
View(note_status_data)
# Join with October 31 ratings on `noteId`
oct_31_data_combined <- oct_31_ratings %>%
left_join(notes_data, by = "noteId") %>%
left_join(note_status_data, by = "noteId")
View(oct_31_data_combined)
oct_31_ratings <- %>%
oct_31_ratings <- oct_31_ratings %>%
rename(ratingCreatedAt = createdAtMillis)
View(oct_31_ratings)
# Join with October 31 ratings on `noteId`
oct_31_data_combined <- oct_31_ratings %>%
left_join(notes_data, by = "noteId") %>%
left_join(note_status_data, by = "noteId")
View(oct_31_data_combined)
write_csv("combined.csv")
write_csv(oct_31_data_combined, "combined.csv")
combined_data <- oct_31_data_combined %>%
mutate(ratingDateTime = as.POSIXct(ratingCreatedAt / 1000, origin = "1970-01-01"),
noteDateTime = as.POSIXct(noteCreatedAt / 1000, origin = "1970-01-01"))
View(combined_data)
View(combined_data)
# Filter for "NOT_HELPFUL" ratings using the correct column name for helpfulness level
not_helpful_data <- combined_data %>%
filter(helpfulnessLevel == "NOT_HELPFUL")
# Group by noteId and 1-hour time windows, and count occurrences
coordinated_behavior <- not_helpful_data %>%
mutate(hour_window = floor_date(ratingDateTime, "hour")) %>%
group_by(noteId, hour_window) %>%
summarize(not_helpful_count = n()) %>%
ungroup()
suspicious_clusters <- coordinated_behavior %>%
filter(not_helpful_count > 5)
print(suspicious_clusters)
View(suspicious_clusters)
# Extract the list of suspicious note IDs
suspicious_note_ids <- suspicious_clusters$noteId
# Filter the combined data for these note IDs and select relevant columns
suspicious_notes <- combined_data %>%
filter(noteId %in% suspicious_note_ids) %>%
select(noteId, summary, noteDateTime, ratingDateTime, helpfulnessLevel, notHelpful)
# Display the suspicious notes to examine their content
print(suspicious_notes)
View(suspicious_notes)
View(suspicious_clusters)
View(suspicious_notes)
View(oct_31_data_combined)
# Group by noteId and 1-hour time windows, and count occurrences
coordinated_behavior <- not_helpful_data %>%
mutate(hour_window = floor_date(ratingDateTime, "30 minutes")) %>%
group_by(noteId, hour_window) %>%
summarize(not_helpful_count = n()) %>%
ungroup()
suspicious_clusters <- coordinated_behavior %>%
filter(not_helpful_count > 5)
View(suspicious_clusters)
View(suspicious_clusters)
# Group by noteId and one hour minute time windows, and count occurrences
coordinated_behavior <- not_helpful_data %>%
mutate(hour_window = floor_date(ratingDateTime, "hour")) %>%
group_by(noteId, hour_window) %>%
summarize(not_helpful_count = n()) %>%
ungroup()
suspicious_clusters <- coordinated_behavior %>%
filter(not_helpful_count > 5)
View(suspicious_clusters)
# Filter data for specific noteId(s) you want to analyze
note_ids_to_plot <- c(1851777319486275858,
1851783417328795676)  # Replace with actual IDs
filtered_data <- combined_data %>%
filter(noteId %in% note_ids_to_plot)
# Convert the rating timestamp to POSIXct format
filtered_data <- filtered_data %>%
mutate(ratingDateTime = as.POSIXct(ratingCreatedAt / 1000, origin = "1970-01-01"))
cumulative_data <- filtered_data %>%
arrange(noteId, ratingDateTime) %>%
mutate(
helpful_cumulative = cumsum(helpful),
not_helpful_cumulative = cumsum(notHelpful)
)
ggplot(cumulative_data, aes(x = ratingDateTime)) +
geom_line(aes(y = helpful_cumulative, color = "Helpful"), size = 1) +
geom_line(aes(y = not_helpful_cumulative, color = "Not Helpful"), size = 1) +
geom_area(aes(y = helpful_cumulative, fill = "Helpful"), alpha = 0.2) +
geom_area(aes(y = not_helpful_cumulative, fill = "Not Helpful"), alpha = 0.2) +
scale_color_manual(values = c("green", "red")) +
scale_fill_manual(values = c("green", "red")) +
labs(title = "Cumulative Votes Over Time",
x = "Date/Time (UTC)",
y = "Votes",
color = "Ratings",
fill = "Ratings") +
facet_wrap(~ noteId, scales = "free_y") +
theme_minimal()
# Filter data for specific noteId(s) you want to analyze
note_ids_to_plot <- c("1851777319486275858",
"1851783417328795676")  # Replace with actual IDs
filtered_data <- combined_data %>%
filter(noteId %in% note_ids_to_plot)
# Convert the rating timestamp to POSIXct format
filtered_data <- filtered_data %>%
mutate(ratingDateTime = as.POSIXct(ratingCreatedAt / 1000, origin = "1970-01-01"))
# Create a cumulative count of "helpful" and "not helpful" ratings over time for each note
cumulative_data <- filtered_data %>%
arrange(noteId, ratingDateTime) %>%
mutate(
helpful_cumulative = cumsum(helpful),
not_helpful_cumulative = cumsum(notHelpful)
)
ggplot(cumulative_data, aes(x = ratingDateTime)) +
geom_line(aes(y = helpful_cumulative, color = "Helpful"), size = 1) +
geom_line(aes(y = not_helpful_cumulative, color = "Not Helpful"), size = 1) +
geom_area(aes(y = helpful_cumulative, fill = "Helpful"), alpha = 0.2) +
geom_area(aes(y = not_helpful_cumulative, fill = "Not Helpful"), alpha = 0.2) +
scale_color_manual(values = c("green", "red")) +
scale_fill_manual(values = c("green", "red")) +
labs(title = "Cumulative Votes Over Time",
x = "Date/Time (UTC)",
y = "Votes",
color = "Ratings",
fill = "Ratings") +
facet_wrap(~ noteId, scales = "free_y") +
theme_minimal()
View(cumulative_data)
View(cumulative_data)
# Convert the rating timestamp to POSIXct format
filtered_data <- filtered_data %>%
mutate(ratingDateTime = as.POSIXct(ratingCreatedAt / 1000, origin = "1970-01-01"))
# Create binary indicators based on helpfulnessLevel
filtered_data <- filtered_data %>%
mutate(
helpful = ifelse(helpfulnessLevel == "HELPFUL", 1, 0),
not_helpful = ifelse(helpfulnessLevel == "NOT_HELPFUL", 1, 0
# Create binary indicators based on helpfulnessLevel
filtered_data <- filtered_data %>%
# Convert the rating timestamp to POSIXct format
filtered_data <- filtered_data %>%
mutate(ratingDateTime = as.POSIXct(ratingCreatedAt / 1000, origin = "1970-01-01"))
# Create binary indicators based on helpfulnessLevel
filtered_data <- filtered_data %>%
mutate(
helpful = ifelse(helpfulnessLevel == "HELPFUL", 1, 0),
not_helpful = ifelse(helpfulnessLevel == "NOT_HELPFUL", 1, 0)
)
cumulative_data <- filtered_data %>%
arrange(noteId, ratingDateTime) %>%
group_by(noteId) %>%
mutate(
helpful_cumulative = cumsum(helpful),
not_helpful_cumulative = cumsum(not_helpful)
) %>%
ungroup()
ggplot(cumulative_data, aes(x = ratingDateTime)) +
geom_line(aes(y = helpful_cumulative, color = "Helpful"), size = 1) +
geom_line(aes(y = not_helpful_cumulative, color = "Not Helpful"), size = 1) +
geom_area(aes(y = helpful_cumulative, fill = "Helpful"), alpha = 0.2) +
geom_area(aes(y = not_helpful_cumulative, fill = "Not Helpful"), alpha = 0.2) +
scale_color_manual(values = c("green", "red")) +
scale_fill_manual(values = c("green", "red")) +
labs(title = "Cumulative Votes Over Time",
x = "Date/Time (UTC)",
y = "Votes",
color = "Ratings",
fill = "Ratings") +
facet_wrap(~ noteId, scales = "free_y") +
theme_minimal()
View(cumulative_data)
View(combined_data)
user_behavior <- combined_data %>%
mutate(
not_helpful = ifelse(helpfulnessLevel == "NOT_HELPFUL", 1, 0),
helpful = ifelse(helpfulnessLevel == "HELPFUL", 1, 0)
) %>%
group_by(raterParticipantId) %>%
summarize(
total_ratings = n(),
total_not_helpful = sum(not_helpful),
total_helpful = sum(helpful),
not_helpful_ratio = total_not_helpful / total_ratings
) %>%
ungroup()
# Filter users with high proportions of "NOT_HELPFUL" ratings (e.g., > 0.8 or 80%)
suspicious_users <- user_behavior %>%
filter(not_helpful_ratio > 0.8)
View(suspicious_users)
negative_nancy <- combined_data %>%
filter(raterParticipantId == "40AF41771EA8630AA64FA2E6180B1A170B516FEEAECF9E8A58AEC7D2F09F5975
")
negative_nancy <- combined_data %>%
filter(raterParticipantId == "40AF41771EA8630AA64FA2E6180B1A170B516FEEAECF9E8A58AEC7D2F09F5975")
View(negative_nancy)
negative_nancy_notes <- note_status_data %>%
filter(noteAuthorParticipantId == "40AF41771EA8630AA64FA2E6180B1A170B516FEEAECF9E8A58AEC7D2F09F5975")
View(negative_nancy_notes)
View(notes_data)
View(negative_nancy)
View(negative_nancy)
View(oct_31_data_combined)
